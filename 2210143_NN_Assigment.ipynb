{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZq8HW8uivm1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5Bd2qgH_OfA",
        "outputId": "80912596-2690-4176-ad73-826a4e1ad13f"
      },
      "outputs": [],
      "source": [
        "# # Mounting the Google Drive to save the the data and results\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ1dgoLW_Lcv"
      },
      "source": [
        "# Accessing the GPU for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbyJTlwpi6eV",
        "outputId": "507ee125-6c89-42e6-86fc-4e452f0d2b61"
      },
      "outputs": [],
      "source": [
        "# If you want to use GPU, you can use the following code to check if GPU is available\n",
        "torch.cuda.get_device_name(0)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  print(\"GPU\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BcviEdHljpy"
      },
      "source": [
        "# Loading in the data and creating dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKhFSNoUlaAV",
        "outputId": "e2b0d006-79e4-431e-ee28-6f6c5c4d18b9"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Normalising the images so they can be compatible with torchvision\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# training set\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "# Shuffle true as we want the training data to be randomised\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                            shuffle=True, num_workers=2)\n",
        "\n",
        "# validation set\n",
        "valset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transform)\n",
        "# No shuffling for the valset\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
        "                                        shuffle=False, num_workers=2)\n",
        "\n",
        "# defining the classes of each image\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "              'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwHeC27b9l3X"
      },
      "source": [
        "# Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XJRctGgt4Oi"
      },
      "outputs": [],
      "source": [
        "class MLP_Conv_Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, K):\n",
        "        super(MLP_Conv_Block, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.K = K\n",
        "        # MLP layer that runs a spatial pool, flattens it, passes it through a linear function and ReLU.\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1,1)), # AdaptiveAvgPool is another way to implement spatial pooling\n",
        "            nn.Flatten(), # Flatten will turn pool of X to (4,3) so it can be passed to linear function\n",
        "            nn.Linear(in_channels, K),\n",
        "            nn.ReLU() # My chose of non-linear activation\n",
        "        )\n",
        "        # Conv Layer made up of K number of independent convolutions \n",
        "        self.convs = nn.ModuleList([nn.Conv2d(in_channels, out_channels, kernel_size=5) for i in range(K)])\n",
        "\n",
        "    def forward(self, x):\n",
        "      # Specifying the batch size = x.size(0) so I can use different batch sizes without errors\n",
        "      batch_size = x.size(0)\n",
        "      # passing the input X through the MLP layer\n",
        "      mlp = self.fc(x)\n",
        "      # passing X through all the convolutions\n",
        "      conv_out = [conv(x) for conv in self.convs]\n",
        "      # mlp[:,1] allows me to index the scalers of the (4, K) tensor made from MLP layer\n",
        "      output = sum([mlp[:, 1].reshape(batch_size, 1, 1, 1) * conv_out[i] for i in range(len(self.convs))])\n",
        "      output = nn.Flatten()(output)\n",
        "      return output\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, in_features, out_classes):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.classify = nn.Sequential(\n",
        "            # final block output needs to pass through pooling before passing to MLP classifier\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            # The first linear layer takes pool of X\n",
        "            nn.Linear(in_features, 512), # 512 is the number of neurons in the first layer\n",
        "            nn.ReLU(), # ReLU removes negative values\n",
        "            nn.Linear(512, 256), # 256 is the number of neurons in the second layer\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128), # 128 is the number of neurons in the third layer\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, out_classes) # 10 is the number of classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        classifier = self.classify(x)\n",
        "        return classifier\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, K):\n",
        "        super(Model, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            MLP_Conv_Block(in_channels, out_channels, K),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        # output multiplied by 28x28 because of the kernel size of 5 after conv layers\n",
        "        # formula - [W - (k+1)] - [32 - (5+1) = 28]\n",
        "        self.classifier = Classifier(out_channels * 28 * 28, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x) # passing the input through the MLP_Conv_Block\n",
        "        x = x.unsqueeze(2).unsqueeze(3) # adding two dimensions to the output of the MLP_Conv_Block\n",
        "        x = self.classifier(x) # passing the output of the MLP_Conv_Block through the classifier\n",
        "        return x\n",
        "\n",
        "# initialising the model to device if possible\n",
        "# net = Model(in_channels=3, out_channels=32, K=10).to(device) \n",
        "\n",
        "# if not\n",
        "net = Model(in_channels=3, out_channels=32, K=10)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loss function and optimiser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3s4afesi0mS"
      },
      "outputs": [],
      "source": [
        "# defining the loss function and the optimizer\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.001) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR_PmZg5-7Xy"
      },
      "source": [
        "# Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dOFxxj6Ui9Pr",
        "outputId": "b8e9b55c-2dda-460e-ee36-3a5d6545f5d7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize lists to store loss and accuracy values\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "\n",
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0 # initialising the running loss\n",
        "    total_train = 0 # initialising the total number of training images\n",
        "    correct_train = 0 # initialising the number of correctly classified training images\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs) # passing the inputs through the model\n",
        "        loss = criterion(outputs, labels) # calculating the loss\n",
        "        loss.backward() # backpropagating the loss\n",
        "        optimizer.step() # updating the weights\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item() # adding the loss to the running loss\n",
        "        _, predicted = torch.max(outputs.data, 1) # getting the predicted class\n",
        "        total_train += labels.size(0) # adding the number of images in the batch to the total number of training images\n",
        "        correct_train += (predicted == labels).sum().item() # adding the number of correctly classified images in the batch to the total number of correctly classified training images\n",
        "        if i % 2000 == 1999:   # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0 # resetting the running loss\n",
        "\n",
        "    # Calculate training accuracy and loss for the epoch\n",
        "    train_acc = 100 * correct_train / total_train  \n",
        "    train_loss = running_loss / len(trainloader)\n",
        "\n",
        "    # Append values to the lists\n",
        "    train_accs.append(train_acc) # appending the training accuracy to the list of training accuracies for graphing\n",
        "    train_losses.append(train_loss) # appending the training loss to the list of training losses for graphing\n",
        "\n",
        "    # Evaluate validation accuracy and loss for the epoch\n",
        "    with torch.no_grad(): \n",
        "        running_val_loss = 0.0\n",
        "        total_val = 0\n",
        "        correct_val = 0\n",
        "\n",
        "        for data in valloader: \n",
        "            images, labels = data \n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = net(images) # passing the images through the model\n",
        "            val_loss = criterion(outputs, labels) # calculating the loss\n",
        "            running_val_loss += val_loss.item() # adding the loss to the running loss\n",
        "            _, predicted = torch.max(outputs.data, 1) # getting the predicted class\n",
        "            total_val += labels.size(0) # adding the number of images in the batch to the total number of validation images\n",
        "            correct_val += (predicted == labels).sum().item() # adding the number of correctly classified images in the batch to the total number of correctly classified validation images\n",
        "\n",
        "        val_acc = 100 * correct_val / total_val # calculating the validation accuracy\n",
        "        val_loss = running_val_loss / len(valloader) # calculating the validation loss\n",
        "\n",
        "        # Append values to the lists\n",
        "        val_accs.append(val_acc) # appending the validation accuracy to the list of validation accuracies for graphing\n",
        "        val_losses.append(val_loss) # appending the validation loss to the list of validation losses for graphing\n",
        "\n",
        "    # print statistics at the end of each epoch\n",
        "    print(f'Epoch {epoch + 1} train loss: {train_loss:.3f}, train acc: {train_acc:.2f}%, val loss: {val_loss:.3f}, val acc: {val_acc:.2f}%')\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Plot loss and accuracy curves\n",
        "epochs = range(1, len(train_losses) + 1) # creating a list of epochs\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, train_losses, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_losses, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('results/Train and Val loss.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, train_accs, 'b', label='Training accuracy')\n",
        "plt.plot(epochs, val_accs, 'r', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('results/Train and Val accuracy.png', dpi=300)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp_EDeEt--fh"
      },
      "source": [
        "# Final Model accuracy on CIFAR-10 Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJJZsbqC5fDO",
        "outputId": "a8102f3f-bb90-491d-fda5-99e30207166a"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "net.eval()  # set the model to evaluation mode\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in valloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # pass the input data through the network\n",
        "        outputs = net(images) \n",
        "        \n",
        "        # determine the predicted class by finding the index with highest value\n",
        "        _, predicted = torch.max(outputs, 1) \n",
        "        \n",
        "        # count the number of correct predictions\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        # count the total number of images\n",
        "        total += labels.size(0)\n",
        "\n",
        "# compute the accuracy of the model\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the {total} test images: {accuracy:.2f} %')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
